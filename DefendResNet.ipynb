{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Sunset\n",
    "2020년 과학 탐구 보고서 발표 대회에 사용될 코드입니다.\n",
    "\n",
    "-----------------------------------------------------------------------------------------\n",
    "\n",
    "FGSM 공격용 이미지와 정상적인 이미지를 분류할 ResNet 코드입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 필요 라이브러리 및 프레임워크 임포트 & 사용 디바이스 선택(CPU or GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 하이퍼 파라미터 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS     = 150\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "MODEL_PATH = './model/PreTrained ResNet/preTrainedResNet_mnist.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cifar_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./.data',\n",
    "                   train=True,\n",
    "                   download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "    batch_size=1, shuffle=True)\n",
    "test_cifar_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./.data',\n",
    "                   train=False, \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))])),\n",
    "    batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(original_img_view):\n",
    "    original_img_view = original_img_view.detach().numpy()\n",
    "    plt.imshow(original_img_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "tensor([4])\n"
     ]
    }
   ],
   "source": [
    "for data, target in train_cifar_loader:\n",
    "    print(data.size())\n",
    "    print(target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) FGSM 공격용 이미지 분류할 DefendResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DefendResNet(nn.Module):\n",
    "    def __init__(self, channels=1, num_classes=2):\n",
    "        super(DefendResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(channels, 16, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(16, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(32, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(64, 2, stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BasicBlock(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.size())\n",
    "        out = self.conv1(x)\n",
    "        #print(out.size())\n",
    "        out = self.bn1(out)\n",
    "        #print(out.size())\n",
    "        out = F.relu(out)\n",
    "        #print(out.size())\n",
    "        out = self.layer1(out)\n",
    "        #print(out.size())\n",
    "        out = self.layer2(out)\n",
    "        #print(out.size())\n",
    "        out = self.layer3(out)\n",
    "        #print(out.size())\n",
    "        out = F.avg_pool2d(out, 7)\n",
    "        #print(out.size())\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #print(out.size())\n",
    "        out = self.linear(out)\n",
    "        #print(out.size())\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(16, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(32, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(64, 2, stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BasicBlock(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, 7)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) 해킹할 ResNet 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "preTrainedResNet = torch.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) FGSM 어택 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(image, epsilon, gradient):\n",
    "    # 기울기값의 원소의 sign 값을 구함\n",
    "    sign_gradient = gradient.sign()\n",
    "    # 이미지 각 픽셀의 값을 sign_gradient 방향으로 epsilon 만큼 조절\n",
    "    perturbed_image = image + epsilon * sign_gradient\n",
    "    # [0,1] 범위를 벗어나는 값을 조절\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPertubedImage(img_tensor, original_image, epsilon, model):\n",
    "    img_tensor = img_tensor#.unsqueeze(0)\n",
    "    target = original_image\n",
    "    img_tensor.requires_grad_(True)\n",
    "    output = model(img_tensor)\n",
    "    loss = F.nll_loss(output, target) \n",
    "    \n",
    "    model.zero_grad()\n",
    "    \n",
    "    loss.requires_grad_(True)\n",
    "    loss.backward()\n",
    "    \n",
    "    gradient = img_tensor.grad.data\n",
    "    perturbed_data = fgsm_attack(img_tensor, epsilon, gradient)\n",
    "    return perturbed_data#.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset): \n",
    "  def __init__(self, cifar, _model, epsilon):\n",
    "    self.x_data = []\n",
    "    self.y_data = None\n",
    "    self.mix = {}\n",
    "    self.model = _model\n",
    "    self.epsilon = epsilon\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(cifar):\n",
    "        self.x_data.append(data)\n",
    "        self.mix[data]=target\n",
    "\n",
    "  def __len__(self): \n",
    "    return len(self.x_data)\n",
    "\n",
    "  def __getitem__(self, idx): \n",
    "    if random.randint(0, 1) == 0 :\n",
    "        #왜곡 X\n",
    "        #print(\"왜곡 X\")\n",
    "        x = self.x_data[idx]\n",
    "        y = torch.tensor(0)\n",
    "    else :\n",
    "        #왜곡 O\n",
    "        #print(\"왜곡 O\")\n",
    "        x = self.x_data[idx]\n",
    "        x = getPertubedImage(torch.tensor(x), torch.tensor(self.mix[x]), self.epsilon, self.model)\n",
    "        y = torch.tensor(1)\n",
    "    \n",
    "    #print(x.size())\n",
    "    #print(y.size())\n",
    "    return x.squeeze(0), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(CustomDataset(train_cifar_loader, preTrainedResNet, 0.5), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(CustomDataset(test_cifar_loader, preTrainedResNet, 0.5), batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "tensor([5])\n",
      "torch.Size([1, 1, 28, 28])\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "for data, target in train_cifar_loader:\n",
    "    print(data.size())\n",
    "    print(target)\n",
    "    break\n",
    "\n",
    "for data, target in DataLoader(CustomDataset(test_cifar_loader, preTrainedResNet, 0.5), batch_size=1, shuffle=True):\n",
    "    print(data.size())\n",
    "    print(target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = (img+1)/2    \n",
    "    img = img.squeeze()\n",
    "    np_img = img.detach().numpy()\n",
    "    plt.imshow(np_img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DefendResNet().to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1,\n",
    "                      momentum=0.9, weight_decay=0.0005)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        print(\"{0}번째 학습 - {1}번 배치\".format(epoch, batch_idx))\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        #print(\"Train\")\n",
    "        output = model(data)\n",
    "        #target=torch.argmax(target, dim=0)\n",
    "        #print(\"--------------------------------------------------------------------------\")\n",
    "        #print(\"결과 : \" + str(output))\n",
    "        #print(\"결과 사이즈 : \" + str(output.size()))\n",
    "        #print(\"타겟 : \" + str(target))\n",
    "        #print(\"타겟 사이즈 : \" + str(target.size()))\n",
    "        #print(\"--------------------------------------------------------------------------\")\n",
    "        \n",
    "        #loss = F.cross_entropy(output, torch.max(target,1)[1])\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "def evaluate(model, test_loader, limit=-1):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    #print(\"test start\")\n",
    "    last_data = None\n",
    "    last_target = None\n",
    "    last_pred = None\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        \n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        output = model(data)\n",
    "\n",
    "        loss = F.cross_entropy(output, target, reduction='sum').item()\n",
    "        test_loss += loss\n",
    "\n",
    "        # 가장 높은 값을 가진 인덱스가 바로 예측값\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()       \n",
    "        last_data = data\n",
    "        last_pred = output.max(1, keepdim=False)[1]\n",
    "        last_target = target\n",
    "        \n",
    "        print(loss)\n",
    "        \n",
    "        if limit != -1 :\n",
    "            if batch_idx + 1 >= limit :\n",
    "                break\n",
    "        \n",
    "    print('--------------------------------------------------------------------------------------------------------')\n",
    "    imshow(last_data[0])\n",
    "    print(\"예측한 답안 : \" + str(pred.data[0]))\n",
    "    print(\"실제 답안 : \" + str(target.data[0]))\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측한 답안 : tensor([0])\n",
      "실제 답안 : tensor(0)\n",
      "\n",
      "[2] Test Loss: 0.0000, Accuracy: 38.40%\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "3번째 학습 - 0번 배치\n",
      "3번째 학습 - 1번 배치\n",
      "3번째 학습 - 2번 배치\n",
      "3번째 학습 - 3번 배치\n",
      "3번째 학습 - 4번 배치\n",
      "3번째 학습 - 5번 배치\n",
      "3번째 학습 - 6번 배치\n",
      "3번째 학습 - 7번 배치\n",
      "3번째 학습 - 8번 배치\n",
      "3번째 학습 - 9번 배치\n",
      "3번째 학습 - 10번 배치\n",
      "3번째 학습 - 11번 배치\n",
      "3번째 학습 - 12번 배치\n",
      "3번째 학습 - 13번 배치\n",
      "3번째 학습 - 14번 배치\n",
      "3번째 학습 - 15번 배치\n",
      "3번째 학습 - 16번 배치\n",
      "3번째 학습 - 17번 배치\n",
      "3번째 학습 - 18번 배치\n",
      "3번째 학습 - 19번 배치\n",
      "3번째 학습 - 20번 배치\n",
      "3번째 학습 - 21번 배치\n",
      "3번째 학습 - 22번 배치\n",
      "3번째 학습 - 23번 배치\n",
      "3번째 학습 - 24번 배치\n",
      "3번째 학습 - 25번 배치\n",
      "3번째 학습 - 26번 배치\n",
      "3번째 학습 - 27번 배치\n",
      "3번째 학습 - 28번 배치\n",
      "3번째 학습 - 29번 배치\n",
      "3번째 학습 - 30번 배치\n",
      "3번째 학습 - 31번 배치\n",
      "3번째 학습 - 32번 배치\n",
      "3번째 학습 - 33번 배치\n",
      "3번째 학습 - 34번 배치\n",
      "3번째 학습 - 35번 배치\n",
      "3번째 학습 - 36번 배치\n",
      "3번째 학습 - 37번 배치\n",
      "3번째 학습 - 38번 배치\n",
      "3번째 학습 - 39번 배치\n",
      "3번째 학습 - 40번 배치\n",
      "3번째 학습 - 41번 배치\n",
      "3번째 학습 - 42번 배치\n",
      "3번째 학습 - 43번 배치\n",
      "3번째 학습 - 44번 배치\n",
      "3번째 학습 - 45번 배치\n",
      "3번째 학습 - 46번 배치\n",
      "3번째 학습 - 47번 배치\n",
      "3번째 학습 - 48번 배치\n",
      "3번째 학습 - 49번 배치\n",
      "3번째 학습 - 50번 배치\n",
      "3번째 학습 - 51번 배치\n",
      "3번째 학습 - 52번 배치\n",
      "3번째 학습 - 53번 배치\n",
      "3번째 학습 - 54번 배치\n",
      "3번째 학습 - 55번 배치\n",
      "3번째 학습 - 56번 배치\n",
      "3번째 학습 - 57번 배치\n",
      "3번째 학습 - 58번 배치\n",
      "3번째 학습 - 59번 배치\n",
      "3번째 학습 - 60번 배치\n",
      "3번째 학습 - 61번 배치\n",
      "3번째 학습 - 62번 배치\n",
      "3번째 학습 - 63번 배치\n",
      "3번째 학습 - 64번 배치\n",
      "3번째 학습 - 65번 배치\n",
      "3번째 학습 - 66번 배치\n",
      "3번째 학습 - 67번 배치\n",
      "3번째 학습 - 68번 배치\n",
      "3번째 학습 - 69번 배치\n",
      "3번째 학습 - 70번 배치\n",
      "3번째 학습 - 71번 배치\n",
      "3번째 학습 - 72번 배치\n",
      "3번째 학습 - 73번 배치\n",
      "3번째 학습 - 74번 배치\n",
      "3번째 학습 - 75번 배치\n",
      "3번째 학습 - 76번 배치\n",
      "3번째 학습 - 77번 배치\n",
      "3번째 학습 - 78번 배치\n",
      "3번째 학습 - 79번 배치\n",
      "3번째 학습 - 80번 배치\n",
      "3번째 학습 - 81번 배치\n",
      "3번째 학습 - 82번 배치\n",
      "3번째 학습 - 83번 배치\n",
      "3번째 학습 - 84번 배치\n",
      "3번째 학습 - 85번 배치\n",
      "3번째 학습 - 86번 배치\n",
      "3번째 학습 - 87번 배치\n",
      "3번째 학습 - 88번 배치\n",
      "3번째 학습 - 89번 배치\n",
      "3번째 학습 - 90번 배치\n",
      "3번째 학습 - 91번 배치\n",
      "3번째 학습 - 92번 배치\n",
      "3번째 학습 - 93번 배치\n",
      "3번째 학습 - 94번 배치\n",
      "3번째 학습 - 95번 배치\n",
      "3번째 학습 - 96번 배치\n",
      "3번째 학습 - 97번 배치\n",
      "3번째 학습 - 98번 배치\n",
      "3번째 학습 - 99번 배치\n",
      "3번째 학습 - 100번 배치\n",
      "3번째 학습 - 101번 배치\n",
      "3번째 학습 - 102번 배치\n",
      "3번째 학습 - 103번 배치\n",
      "3번째 학습 - 104번 배치\n",
      "3번째 학습 - 105번 배치\n",
      "3번째 학습 - 106번 배치\n",
      "3번째 학습 - 107번 배치\n",
      "3번째 학습 - 108번 배치\n",
      "3번째 학습 - 109번 배치\n",
      "3번째 학습 - 110번 배치\n",
      "3번째 학습 - 111번 배치\n",
      "3번째 학습 - 112번 배치\n",
      "3번째 학습 - 113번 배치\n",
      "3번째 학습 - 114번 배치\n",
      "3번째 학습 - 115번 배치\n",
      "3번째 학습 - 116번 배치\n",
      "3번째 학습 - 117번 배치\n",
      "3번째 학습 - 118번 배치\n",
      "3번째 학습 - 119번 배치\n",
      "3번째 학습 - 120번 배치\n",
      "3번째 학습 - 121번 배치\n",
      "3번째 학습 - 122번 배치\n",
      "3번째 학습 - 123번 배치\n",
      "3번째 학습 - 124번 배치\n",
      "3번째 학습 - 125번 배치\n",
      "3번째 학습 - 126번 배치\n",
      "3번째 학습 - 127번 배치\n",
      "3번째 학습 - 128번 배치\n",
      "3번째 학습 - 129번 배치\n",
      "3번째 학습 - 130번 배치\n",
      "3번째 학습 - 131번 배치\n",
      "3번째 학습 - 132번 배치\n",
      "3번째 학습 - 133번 배치\n",
      "3번째 학습 - 134번 배치\n",
      "3번째 학습 - 135번 배치\n",
      "3번째 학습 - 136번 배치\n",
      "3번째 학습 - 137번 배치\n",
      "3번째 학습 - 138번 배치\n",
      "3번째 학습 - 139번 배치\n",
      "3번째 학습 - 140번 배치\n",
      "3번째 학습 - 141번 배치\n",
      "3번째 학습 - 142번 배치\n",
      "3번째 학습 - 143번 배치\n",
      "3번째 학습 - 144번 배치\n",
      "3번째 학습 - 145번 배치\n",
      "3번째 학습 - 146번 배치\n",
      "3번째 학습 - 147번 배치\n",
      "3번째 학습 - 148번 배치\n",
      "3번째 학습 - 149번 배치\n",
      "3번째 학습 - 150번 배치\n",
      "3번째 학습 - 151번 배치\n",
      "3번째 학습 - 152번 배치\n",
      "3번째 학습 - 153번 배치\n",
      "3번째 학습 - 154번 배치\n",
      "3번째 학습 - 155번 배치\n",
      "3번째 학습 - 156번 배치\n",
      "3번째 학습 - 157번 배치\n",
      "3번째 학습 - 158번 배치\n",
      "3번째 학습 - 159번 배치\n",
      "3번째 학습 - 160번 배치\n",
      "3번째 학습 - 161번 배치\n",
      "3번째 학습 - 162번 배치\n",
      "3번째 학습 - 163번 배치\n",
      "3번째 학습 - 164번 배치\n",
      "3번째 학습 - 165번 배치\n",
      "3번째 학습 - 166번 배치\n",
      "3번째 학습 - 167번 배치\n",
      "3번째 학습 - 168번 배치\n",
      "3번째 학습 - 169번 배치\n",
      "3번째 학습 - 170번 배치\n",
      "3번째 학습 - 171번 배치\n",
      "3번째 학습 - 172번 배치\n",
      "3번째 학습 - 173번 배치\n",
      "3번째 학습 - 174번 배치\n",
      "3번째 학습 - 175번 배치\n",
      "3번째 학습 - 176번 배치\n",
      "3번째 학습 - 177번 배치\n",
      "3번째 학습 - 178번 배치\n",
      "3번째 학습 - 179번 배치\n",
      "3번째 학습 - 180번 배치\n",
      "3번째 학습 - 181번 배치\n",
      "3번째 학습 - 182번 배치\n",
      "3번째 학습 - 183번 배치\n",
      "3번째 학습 - 184번 배치\n",
      "3번째 학습 - 185번 배치\n",
      "3번째 학습 - 186번 배치\n",
      "3번째 학습 - 187번 배치\n",
      "3번째 학습 - 188번 배치\n",
      "3번째 학습 - 189번 배치\n",
      "3번째 학습 - 190번 배치\n",
      "3번째 학습 - 191번 배치\n",
      "3번째 학습 - 192번 배치\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-2bb707b67133>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malready\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-2e7793401b8b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#print(\"Train\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;31m#target=torch.argmax(target, dim=0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#print(\"--------------------------------------------------------------------------\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-56-d30344f11783>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m#print(out.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;31m#print(out.size())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-56-d30344f11783>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    348\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    349\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 350\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "already = 1\n",
    "for epoch in range(already, EPOCHS + 1):\n",
    "    scheduler.step()\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    clear_output(wait=True)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader, limit=30)\n",
    "    \n",
    "    print('\\n[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
    "          epoch, test_loss, test_accuracy))\n",
    "    print('--------------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LHZ\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.69832611083984\n",
      "--------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측한 답안 : tensor([0])\n",
      "실제 답안 : tensor(1)\n",
      "0.009069832611083984\n",
      "0.51\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = evaluate(model, test_loader, limit=1)\n",
    "print(test_loss)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '.\\\\Defend ResNet\\\\DefendResNet.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
