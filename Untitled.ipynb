{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Sunset\n",
    "2020년 과학 탐구 보고서 발표 대회에 사용될 코드입니다.\n",
    "\n",
    "-----------------------------------------------------------------------------------------\n",
    "\n",
    "FGSM 공격용 이미지를 생성할 ResNet을 학습시킵니다.\n",
    "사용할 데이터셋은 CIFAR-100입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS     = 300\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR100('./.data',\n",
    "                   train=True,\n",
    "                   download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.RandomCrop(32, padding=4),\n",
    "                       transforms.RandomHorizontalFlip(),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                            (0.5, 0.5, 0.5))])),\n",
    "    batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR100('./.data',\n",
    "                   train=False, \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                            (0.5, 0.5, 0.5))])),\n",
    "    batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(16, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(32, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(64, 2, stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BasicBlock(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet().to(DEVICE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1,\n",
    "                      momentum=0.9, weight_decay=0.0005)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if batch_idx >= BATCH_SIZE+1 :\n",
    "            break\n",
    "        print(\"{0}번째 학습 - 배치 : {1}\".format(epoch, batch_idx))\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "\n",
    "            # 배치 오차를 합산\n",
    "            test_loss += F.cross_entropy(output, target,\n",
    "                                         reduction='sum').item()\n",
    "\n",
    "            # 가장 높은 값을 가진 인덱스가 바로 예측값\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72] Test Loss: 1.4648, Accuracy: 59.22%\n",
      "73번째 학습 - 배치 : 0\n",
      "73번째 학습 - 배치 : 1\n",
      "73번째 학습 - 배치 : 2\n",
      "73번째 학습 - 배치 : 3\n",
      "73번째 학습 - 배치 : 4\n",
      "73번째 학습 - 배치 : 5\n",
      "73번째 학습 - 배치 : 6\n",
      "73번째 학습 - 배치 : 7\n",
      "73번째 학습 - 배치 : 8\n",
      "73번째 학습 - 배치 : 9\n",
      "73번째 학습 - 배치 : 10\n",
      "73번째 학습 - 배치 : 11\n",
      "73번째 학습 - 배치 : 12\n",
      "73번째 학습 - 배치 : 13\n",
      "73번째 학습 - 배치 : 14\n",
      "73번째 학습 - 배치 : 15\n",
      "73번째 학습 - 배치 : 16\n",
      "73번째 학습 - 배치 : 17\n",
      "73번째 학습 - 배치 : 18\n",
      "73번째 학습 - 배치 : 19\n",
      "73번째 학습 - 배치 : 20\n",
      "73번째 학습 - 배치 : 21\n",
      "73번째 학습 - 배치 : 22\n",
      "73번째 학습 - 배치 : 23\n",
      "73번째 학습 - 배치 : 24\n",
      "73번째 학습 - 배치 : 25\n",
      "73번째 학습 - 배치 : 26\n",
      "73번째 학습 - 배치 : 27\n",
      "73번째 학습 - 배치 : 28\n",
      "73번째 학습 - 배치 : 29\n",
      "73번째 학습 - 배치 : 30\n",
      "73번째 학습 - 배치 : 31\n",
      "73번째 학습 - 배치 : 32\n",
      "73번째 학습 - 배치 : 33\n",
      "73번째 학습 - 배치 : 34\n",
      "73번째 학습 - 배치 : 35\n",
      "73번째 학습 - 배치 : 36\n",
      "73번째 학습 - 배치 : 37\n",
      "73번째 학습 - 배치 : 38\n",
      "73번째 학습 - 배치 : 39\n",
      "73번째 학습 - 배치 : 40\n",
      "73번째 학습 - 배치 : 41\n",
      "73번째 학습 - 배치 : 42\n",
      "73번째 학습 - 배치 : 43\n",
      "73번째 학습 - 배치 : 44\n",
      "73번째 학습 - 배치 : 45\n",
      "73번째 학습 - 배치 : 46\n",
      "73번째 학습 - 배치 : 47\n",
      "73번째 학습 - 배치 : 48\n",
      "73번째 학습 - 배치 : 49\n",
      "73번째 학습 - 배치 : 50\n",
      "73번째 학습 - 배치 : 51\n",
      "73번째 학습 - 배치 : 52\n",
      "73번째 학습 - 배치 : 53\n",
      "73번째 학습 - 배치 : 54\n",
      "73번째 학습 - 배치 : 55\n",
      "73번째 학습 - 배치 : 56\n",
      "73번째 학습 - 배치 : 57\n",
      "73번째 학습 - 배치 : 58\n",
      "73번째 학습 - 배치 : 59\n",
      "73번째 학습 - 배치 : 60\n",
      "73번째 학습 - 배치 : 61\n",
      "73번째 학습 - 배치 : 62\n",
      "73번째 학습 - 배치 : 63\n",
      "73번째 학습 - 배치 : 64\n",
      "73번째 학습 - 배치 : 65\n",
      "73번째 학습 - 배치 : 66\n",
      "73번째 학습 - 배치 : 67\n",
      "73번째 학습 - 배치 : 68\n",
      "73번째 학습 - 배치 : 69\n",
      "73번째 학습 - 배치 : 70\n",
      "73번째 학습 - 배치 : 71\n",
      "73번째 학습 - 배치 : 72\n",
      "73번째 학습 - 배치 : 73\n",
      "73번째 학습 - 배치 : 74\n",
      "73번째 학습 - 배치 : 75\n",
      "73번째 학습 - 배치 : 76\n",
      "73번째 학습 - 배치 : 77\n",
      "73번째 학습 - 배치 : 78\n",
      "73번째 학습 - 배치 : 79\n",
      "73번째 학습 - 배치 : 80\n",
      "73번째 학습 - 배치 : 81\n",
      "73번째 학습 - 배치 : 82\n",
      "73번째 학습 - 배치 : 83\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    scheduler.step()\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    clear_output(wait=True)\n",
    "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
    "          epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '.\\\\PreTrained ResNet\\\\preTrainedResNet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 텐서 모양: torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('imagenet_samples/corgie.jpg')\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224), Image.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "img_tensor = img_transforms(img)\n",
    "img_tensor = img_tensor.unsqueeze(0)\n",
    "\n",
    "print(\"이미지 텐서 모양:\", img_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(image, epsilon, gradient):\n",
    "    # 기울기값의 원소의 sign 값을 구함\n",
    "    sign_gradient = gradient.sign()\n",
    "    # 이미지 각 픽셀의 값을 sign_gradient 방향으로 epsilon 만큼 조절\n",
    "    perturbed_image = image + epsilon * sign_gradient\n",
    "    # [0,1] 범위를 벗어나는 값을 조절\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor.requires_grad_(True)\n",
    "\n",
    "output = model(img_tensor)\n",
    "\n",
    "loss = F.nll_loss(output, torch.tensor([])) \n",
    "\n",
    "model.zero_grad()\n",
    "loss.backward()\n",
    "\n",
    "gradient = img_tensor.grad.data\n",
    "\n",
    "epsilon = 0.03\n",
    "perturbed_data = fgsm_attack(img_tensor, epsilon, gradient)\n",
    "\n",
    "output = model(perturbed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(img_tensor)\n",
    "prediction = output.max(1, keepdim=False)[1]\n",
    "prediction_idx = prediction.item()\n",
    "print(\"예측된 레이블 번호:\", prediction_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_prediction = output.max(1, keepdim=True)[1]\n",
    "perturbed_prediction_idx = perturbed_prediction.item()\n",
    "print(\"예측된 레이블 번호:\", perturbed_prediction_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
